{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b0e4620",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd19550",
   "metadata": {},
   "source": [
    "## Import Libraries and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1faace61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss, precision_score\n",
    "from sklearn.model_selection import  GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train = pd.read_feather('Final_train_dataset.feather')\n",
    "validation = pd.read_feather('Final_validation_dataset.feather')\n",
    "test = pd.read_feather('Final_test_dataset.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fa602d",
   "metadata": {},
   "source": [
    "## Split Data into X(Feature) and Y(Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f4e98851",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['is_duplicate'],  axis=1)\n",
    "y_train = train['is_duplicate']\n",
    "X_val = validation.drop(['is_duplicate'],  axis=1)\n",
    "y_val = validation['is_duplicate']\n",
    "X_test = test.drop(['is_duplicate'],  axis=1)\n",
    "y_test = test['is_duplicate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493c5b76",
   "metadata": {},
   "source": [
    "## Drop Unecessary Columns (Non Important Features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8d4df37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "impt_feat = ['freq_q2', 'freq_q1+q2', 'freq_q1', 'jaccard_dist', 'Levenshtein',\n",
    "       'diff_tfidf_L2', 'diff_tfidf_L1', 'common_ratio', 'levenshtein',\n",
    "       'fuzz_qratio', 'dist_canberra', 'length_diff', 'lc_substring',\n",
    "       'lc_subsequence', 'freq_q1-q2', 'same_ending', 'wmdistance',\n",
    "       'dist_cosine', 'dist_cityblock', 'dist_euclidean', 'dist_minkowski',\n",
    "       'q1_vec_0', 'q1_vec_1', 'q1_vec_2', 'q1_vec_3', 'q1_vec_4', 'q2_vec_0',\n",
    "       'q2_vec_1', 'q2_vec_2', 'q2_vec_3', 'q2_vec_4', 'diff_tfidf_L2_norm', 'diff_tfidf_L1_norm',\n",
    "       'q2_word_to_vec', 'total_length']\n",
    "\n",
    "X_train = X_train[impt_feat]\n",
    "X_val = X_val[impt_feat]\n",
    "X_test = X_test[impt_feat]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d767de8",
   "metadata": {},
   "source": [
    "## Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ea162c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "scale = X_train.columns.tolist()\n",
    "\n",
    "X_train_scaled = X_train.copy()\n",
    "X_val_scaled = X_val.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[scale] = StandardScaler().fit_transform(X_train[scale])\n",
    "X_val_scaled[scale] = StandardScaler().fit_transform(X_val_scaled[scale])\n",
    "X_test_scaled[scale] = StandardScaler().fit_transform(X_test_scaled[scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0ddef0",
   "metadata": {},
   "source": [
    "## 1. Building Base XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bff5b55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=1, ...)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(random_state = 1)\n",
    "xgb.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d67b90d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train log loss is: 0.28676031712518535\n",
      "The train precision is: 0.8407997462242038\n",
      "The validation log loss is: 0.36527218022652663\n",
      "The validation precision is: 0.8354134865762772\n",
      "The test log loss is: 0.36119589164132737\n",
      "The test precision is: 0.8092410314813309\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, x_train, y_train, x_val, y_val, x_test, y_test):\n",
    "    preds_train = model.predict(x_train)\n",
    "    preds_prob_train = model.predict_proba(x_train)\n",
    "    preds_val = model.predict(x_val)\n",
    "    preds_prob_val = model.predict_proba(x_val)\n",
    "    preds_test = model.predict(x_test)\n",
    "    preds_prob_test = model.predict_proba(x_test)\n",
    "    print(\"The train log loss is:\", log_loss(y_train, preds_prob_train))\n",
    "    print(\"The train precision is:\", precision_score(y_train, preds_train))\n",
    "    print(\"The validation log loss is:\", log_loss(y_val, preds_prob_val))\n",
    "    print(\"The validation precision is:\", precision_score(y_val, preds_val))\n",
    "    print(\"The test log loss is:\", log_loss(y_test, preds_prob_test))\n",
    "    print(\"The test precision is:\", precision_score(y_test, preds_test))\n",
    "    return preds_train, preds_prob_train, preds_val, preds_prob_val, preds_test, preds_prob_test\n",
    "\n",
    "\n",
    "preds_train, preds_prob_train, preds_val, preds_prob_val, preds_test, preds_prob_test = evaluate(xgb, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56982871",
   "metadata": {},
   "source": [
    "## 2 Tune hyperparameter to boost predictive power"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdbced9",
   "metadata": {},
   "source": [
    "### Set initial value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c2f2872f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.65071+0.00009\ttest-logloss:0.65083+0.00023\n",
      "[50]\ttrain-logloss:0.36455+0.00024\ttest-logloss:0.36925+0.00311\n",
      "[100]\ttrain-logloss:0.34782+0.00043\ttest-logloss:0.35691+0.00301\n",
      "[150]\ttrain-logloss:0.33789+0.00049\ttest-logloss:0.35140+0.00301\n",
      "[200]\ttrain-logloss:0.33076+0.00038\ttest-logloss:0.34849+0.00303\n",
      "[250]\ttrain-logloss:0.32432+0.00044\ttest-logloss:0.34640+0.00304\n",
      "[300]\ttrain-logloss:0.31846+0.00049\ttest-logloss:0.34496+0.00308\n",
      "[350]\ttrain-logloss:0.31319+0.00044\ttest-logloss:0.34390+0.00302\n",
      "[400]\ttrain-logloss:0.30838+0.00045\ttest-logloss:0.34318+0.00308\n",
      "[450]\ttrain-logloss:0.30402+0.00058\ttest-logloss:0.34257+0.00311\n",
      "[500]\ttrain-logloss:0.30038+0.00056\ttest-logloss:0.34217+0.00309\n",
      "[550]\ttrain-logloss:0.29739+0.00055\ttest-logloss:0.34188+0.00313\n",
      "[600]\ttrain-logloss:0.29509+0.00053\ttest-logloss:0.34171+0.00320\n",
      "[650]\ttrain-logloss:0.29319+0.00065\ttest-logloss:0.34159+0.00320\n",
      "[700]\ttrain-logloss:0.29160+0.00075\ttest-logloss:0.34146+0.00321\n",
      "[750]\ttrain-logloss:0.29007+0.00074\ttest-logloss:0.34137+0.00324\n",
      "[800]\ttrain-logloss:0.28879+0.00054\ttest-logloss:0.34130+0.00323\n",
      "[850]\ttrain-logloss:0.28746+0.00051\ttest-logloss:0.34123+0.00322\n",
      "[900]\ttrain-logloss:0.28636+0.00051\ttest-logloss:0.34118+0.00322\n",
      "[950]\ttrain-logloss:0.28545+0.00043\ttest-logloss:0.34114+0.00320\n",
      "[999]\ttrain-logloss:0.28456+0.00061\ttest-logloss:0.34107+0.00319\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "params = {}\n",
    "params[\"objective\"] = \"binary:logistic\"\n",
    "params[\"eval_metric\"] = \"logloss\"\n",
    "params[\"eta\"] = 0.1\n",
    "params[\"gamma\"] = 2\n",
    "params[\"tree_method\"] = \"gpu_hist\"\n",
    "params[\"max_bin\"] = 256\n",
    "params[\"max_depth\"] = 6 \n",
    "params[\"min_child_weight\"] = 3\n",
    "params[\"subsample\"] = 0.9\n",
    "params[\"colsample_bytree\"] = 0.7\n",
    "params['learning_rate'] = 0.1\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train_scaled, label = y_train)\n",
    "model1 = xgb.cv(params, dtrain, num_boost_round = 1000, nfold = 10, \n",
    "                early_stopping_rounds = 200, verbose_eval = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe25a943",
   "metadata": {},
   "source": [
    "## Tune max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4b994c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>999</th>\n",
       "      <th>999</th>\n",
       "      <th>999</th>\n",
       "      <th>999</th>\n",
       "      <th>999</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train-logloss-mean</th>\n",
       "      <td>0.299813</td>\n",
       "      <td>0.301003</td>\n",
       "      <td>0.301562</td>\n",
       "      <td>0.280293</td>\n",
       "      <td>0.283133</td>\n",
       "      <td>0.283877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train-logloss-std</th>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.001268</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.000760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test-logloss-mean</th>\n",
       "      <td>0.342355</td>\n",
       "      <td>0.342515</td>\n",
       "      <td>0.342678</td>\n",
       "      <td>0.341741</td>\n",
       "      <td>0.341739</td>\n",
       "      <td>0.341820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test-logloss-std</th>\n",
       "      <td>0.002013</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.001820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         999       999       999       999       999       999\n",
       "train-logloss-mean  0.299813  0.301003  0.301562  0.280293  0.283133  0.283877\n",
       "train-logloss-std   0.000373  0.000531  0.000602  0.001268  0.000756  0.000760\n",
       "test-logloss-mean   0.342355  0.342515  0.342678  0.341741  0.341739  0.341820\n",
       "test-logloss-std    0.002013  0.002036  0.001845  0.002020  0.001931  0.001820"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {}\n",
    "params[\"objective\"] = \"binary:logistic\"\n",
    "params[\"eval_metric\"] = \"logloss\"\n",
    "params[\"eta\"] = 0.1\n",
    "params[\"gamma\"] = 2\n",
    "params[\"tree_method\"] = \"gpu_hist\"\n",
    "params[\"max_bin\"] = 256\n",
    "#params[\"max_depth\"] = 6 \n",
    "#params[\"min_child_weight\"] = 3\n",
    "params[\"subsample\"] = 0.9\n",
    "params[\"colsample_bytree\"] = 0.7\n",
    "params['learning_rate'] = 0.1\n",
    "\n",
    "evaluation_list = []\n",
    "for depth in [5, 6]:\n",
    "    for child_weight in [1, 3, 4]:\n",
    "        params = {**params, **{\"max_depth\": depth, \"min_child_weight\": child_weight}}\n",
    "        evaluation = xgb.cv(params, dtrain, num_boost_round = 1000, nfold = 6, early_stopping_rounds = 100)\n",
    "        evaluation_list.append(evaluation)\n",
    "        \n",
    "evaluation_panel = pd.DataFrame()\n",
    "for evaluation in evaluation_list:\n",
    "    evaluation_panel = pd.concat([evaluation_panel, evaluation.iloc[-1, :]], axis = 1)\n",
    "evaluation_panel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0174ce57",
   "metadata": {},
   "source": [
    "Max depth = 6\n",
    "min weight = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9f0f9a",
   "metadata": {},
   "source": [
    "## Tune gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f9770aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>999</th>\n",
       "      <th>830</th>\n",
       "      <th>999</th>\n",
       "      <th>999</th>\n",
       "      <th>999</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train-logloss-mean</th>\n",
       "      <td>0.258529</td>\n",
       "      <td>0.270993</td>\n",
       "      <td>0.283877</td>\n",
       "      <td>0.303370</td>\n",
       "      <td>0.315180</td>\n",
       "      <td>0.322529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train-logloss-std</th>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test-logloss-mean</th>\n",
       "      <td>0.341388</td>\n",
       "      <td>0.341488</td>\n",
       "      <td>0.341820</td>\n",
       "      <td>0.343123</td>\n",
       "      <td>0.344749</td>\n",
       "      <td>0.346142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test-logloss-std</th>\n",
       "      <td>0.001851</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.002000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         999       830       999       999       999       999\n",
       "train-logloss-mean  0.258529  0.270993  0.283877  0.303370  0.315180  0.322529\n",
       "train-logloss-std   0.000493  0.000250  0.000760  0.000843  0.000449  0.000463\n",
       "test-logloss-mean   0.341388  0.341488  0.341820  0.343123  0.344749  0.346142\n",
       "test-logloss-std    0.001851  0.001869  0.001820  0.002048  0.001908  0.002000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {}\n",
    "params[\"objective\"] = \"binary:logistic\"\n",
    "params[\"eval_metric\"] = \"logloss\"\n",
    "params[\"eta\"] = 0.1\n",
    "#params[\"gamma\"] = 2\n",
    "params[\"tree_method\"] = \"gpu_hist\"\n",
    "params[\"max_bin\"] = 256\n",
    "params[\"max_depth\"] = 6 \n",
    "params[\"min_child_weight\"] = 4\n",
    "params[\"subsample\"] = 0.9\n",
    "params[\"colsample_bytree\"] = 0.7\n",
    "params['learning_rate'] = 0.1\n",
    "\n",
    "evaluation_list = []\n",
    "for gamma in [0, 1, 2, 3, 4, 5]:\n",
    "    params = {**params, **{\"gamma\": gamma}}\n",
    "    evaluation = xgb.cv(params, dtrain, num_boost_round = 1000, nfold = 6, early_stopping_rounds = 100)\n",
    "    evaluation_list.append(evaluation)\n",
    "        \n",
    "evaluation_panel = pd.DataFrame()\n",
    "for evaluation in evaluation_list:\n",
    "    evaluation_panel = pd.concat([evaluation_panel, evaluation.iloc[-1, :]], axis = 1)\n",
    "evaluation_panel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7944912e",
   "metadata": {},
   "source": [
    "Gamma = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b959c5e",
   "metadata": {},
   "source": [
    "##  Tune subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5b3723b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>652</th>\n",
       "      <th>638</th>\n",
       "      <th>658</th>\n",
       "      <th>813</th>\n",
       "      <th>806</th>\n",
       "      <th>750</th>\n",
       "      <th>888</th>\n",
       "      <th>894</th>\n",
       "      <th>788</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train-logloss-mean</th>\n",
       "      <td>0.283113</td>\n",
       "      <td>0.282735</td>\n",
       "      <td>0.280057</td>\n",
       "      <td>0.269761</td>\n",
       "      <td>0.268515</td>\n",
       "      <td>0.271965</td>\n",
       "      <td>0.264927</td>\n",
       "      <td>0.262667</td>\n",
       "      <td>0.270172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train-logloss-std</th>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test-logloss-mean</th>\n",
       "      <td>0.342636</td>\n",
       "      <td>0.342925</td>\n",
       "      <td>0.342477</td>\n",
       "      <td>0.342159</td>\n",
       "      <td>0.342126</td>\n",
       "      <td>0.341971</td>\n",
       "      <td>0.341612</td>\n",
       "      <td>0.341395</td>\n",
       "      <td>0.341673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test-logloss-std</th>\n",
       "      <td>0.001979</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>0.002241</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>0.002266</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.002147</td>\n",
       "      <td>0.001973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         652       638       658       813       806  \\\n",
       "train-logloss-mean  0.283113  0.282735  0.280057  0.269761  0.268515   \n",
       "train-logloss-std   0.000421  0.000328  0.000446  0.000670  0.000437   \n",
       "test-logloss-mean   0.342636  0.342925  0.342477  0.342159  0.342126   \n",
       "test-logloss-std    0.001979  0.001941  0.002241  0.002194  0.001861   \n",
       "\n",
       "                         750       888       894       788  \n",
       "train-logloss-mean  0.271965  0.264927  0.262667  0.270172  \n",
       "train-logloss-std   0.000522  0.000638  0.000486  0.000335  \n",
       "test-logloss-mean   0.341971  0.341612  0.341395  0.341673  \n",
       "test-logloss-std    0.002266  0.001908  0.002147  0.001973  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {}\n",
    "params[\"objective\"] = \"binary:logistic\"\n",
    "params[\"eval_metric\"] = \"logloss\"\n",
    "params[\"eta\"] = 0.1\n",
    "params[\"gamma\"] = 0\n",
    "params[\"tree_method\"] = \"gpu_hist\"\n",
    "params[\"max_bin\"] = 256\n",
    "params[\"max_depth\"] = 6 \n",
    "params[\"min_child_weight\"] = 4\n",
    "#params[\"subsample\"] = 0.9\n",
    "#params[\"colsample_bytree\"] = 0.8\n",
    "params['learning_rate'] = 0.1\n",
    "\n",
    "evaluation_list = []\n",
    "for row in [0.7, 0.8, 0.9]:\n",
    "    for col in [0.7, 0.8, 0.9]:\n",
    "        params = {**params, **{\"subsample\": row, \"colsample_bytree\": col}}\n",
    "        evaluation = xgb.cv(params, dtrain, num_boost_round = 1000, nfold = 6, \n",
    "                            early_stopping_rounds = 100)\n",
    "        evaluation_list.append(evaluation)\n",
    "\n",
    "evaluation_panel = pd.DataFrame()\n",
    "for evaluation in evaluation_list:\n",
    "    evaluation_panel = pd.concat([evaluation_panel, evaluation.iloc[-1, :]], axis = 1)\n",
    "evaluation_panel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a238d6aa",
   "metadata": {},
   "source": [
    "subsample = 0.9, colsample_bytree = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6688bd58",
   "metadata": {},
   "source": [
    "## Tune Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d91734a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>999</th>\n",
       "      <th>999</th>\n",
       "      <th>306</th>\n",
       "      <th>168</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train-logloss-mean</th>\n",
       "      <td>0.347222</td>\n",
       "      <td>0.281152</td>\n",
       "      <td>0.290207</td>\n",
       "      <td>0.299174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train-logloss-std</th>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.000539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test-logloss-mean</th>\n",
       "      <td>0.356846</td>\n",
       "      <td>0.341734</td>\n",
       "      <td>0.344974</td>\n",
       "      <td>0.347961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test-logloss-std</th>\n",
       "      <td>0.001580</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.001714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         999       999       306       168\n",
       "train-logloss-mean  0.347222  0.281152  0.290207  0.299174\n",
       "train-logloss-std   0.000333  0.000581  0.000690  0.000539\n",
       "test-logloss-mean   0.356846  0.341734  0.344974  0.347961\n",
       "test-logloss-std    0.001580  0.001936  0.002162  0.001714"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {}\n",
    "params[\"objective\"] = \"binary:logistic\"\n",
    "params[\"eval_metric\"] = \"logloss\"\n",
    "params[\"eta\"] = 0.1\n",
    "params[\"gamma\"] = 2\n",
    "params[\"tree_method\"] = \"gpu_hist\"\n",
    "params[\"max_bin\"] = 256\n",
    "params[\"max_depth\"] = 6 \n",
    "params[\"min_child_weight\"] = 4\n",
    "params[\"subsample\"] = 0.9\n",
    "params[\"colsample_bytree\"] = 0.8\n",
    "#params['learning_rate'] = 0.1\n",
    "\n",
    "evaluation_list = []\n",
    "for learning_rate in [0.01, 0.1, 0.2, 0.3]:\n",
    "    params = {**params, **{\"learning_rate\": learning_rate}}\n",
    "    evaluation = xgb.cv(params, dtrain, num_boost_round = 1000, nfold = 6, early_stopping_rounds = 100)\n",
    "    evaluation_list.append(evaluation)\n",
    "\n",
    "evaluation_panel = pd.DataFrame()\n",
    "for evaluation in evaluation_list:\n",
    "    evaluation_panel = pd.concat([evaluation_panel, evaluation.iloc[-1, :]], axis = 1)\n",
    "evaluation_panel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca295a70",
   "metadata": {},
   "source": [
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfa058d",
   "metadata": {},
   "source": [
    "## Tune Max bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6113591f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>999</th>\n",
       "      <th>999</th>\n",
       "      <th>999</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train-logloss-mean</th>\n",
       "      <td>0.283256</td>\n",
       "      <td>0.282271</td>\n",
       "      <td>0.281919</td>\n",
       "      <td>0.281207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train-logloss-std</th>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.001068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test-logloss-mean</th>\n",
       "      <td>0.341643</td>\n",
       "      <td>0.341637</td>\n",
       "      <td>0.341871</td>\n",
       "      <td>0.341950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test-logloss-std</th>\n",
       "      <td>0.001943</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.002137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         999       999       999       999\n",
       "train-logloss-mean  0.283256  0.282271  0.281919  0.281207\n",
       "train-logloss-std   0.000838  0.000828  0.000820  0.001068\n",
       "test-logloss-mean   0.341643  0.341637  0.341871  0.341950\n",
       "test-logloss-std    0.001943  0.001898  0.002005  0.002137"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {}\n",
    "params[\"objective\"] = \"binary:logistic\"\n",
    "params[\"eval_metric\"] = \"logloss\"\n",
    "params[\"eta\"] = 0.1\n",
    "params[\"gamma\"] = 2\n",
    "params[\"tree_method\"] = \"gpu_hist\"\n",
    "#params[\"max_bin\"] = 256\n",
    "params[\"max_depth\"] = 6 \n",
    "params[\"min_child_weight\"] = 4\n",
    "params[\"subsample\"] = 0.9\n",
    "params[\"colsample_bytree\"] = 0.8\n",
    "params['learning_rate'] = 0.1\n",
    "\n",
    "evaluation_list = []\n",
    "for bin in [200, 230, 256, 280]:\n",
    "    params = {**params, **{\"max_bin\": bin}}\n",
    "    evaluation = xgb.cv(params, dtrain, num_boost_round = 1000, nfold = 6, early_stopping_rounds = 100)\n",
    "    evaluation_list.append(evaluation)\n",
    "\n",
    "evaluation_panel = pd.DataFrame()\n",
    "for evaluation in evaluation_list:\n",
    "    evaluation_panel = pd.concat([evaluation_panel, evaluation.iloc[-1, :]], axis = 1)\n",
    "evaluation_panel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53576ec1",
   "metadata": {},
   "source": [
    "max depth = 230"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639d0676",
   "metadata": {},
   "source": [
    "## 3. Building Final XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a50303ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.8,\n",
       "              early_stopping_rounds=None, enable_categorical=False, eta=0.1,\n",
       "              eval_metric=&#x27;logloss&#x27;, feature_types=None, gamma=2, gpu_id=0,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.1, max_bin=230,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=6, max_leaves=0, min_child_weight=4, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=1000, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.8,\n",
       "              early_stopping_rounds=None, enable_categorical=False, eta=0.1,\n",
       "              eval_metric=&#x27;logloss&#x27;, feature_types=None, gamma=2, gpu_id=0,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.1, max_bin=230,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=6, max_leaves=0, min_child_weight=4, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=1000, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.8,\n",
       "              early_stopping_rounds=None, enable_categorical=False, eta=0.1,\n",
       "              eval_metric='logloss', feature_types=None, gamma=2, gpu_id=0,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.1, max_bin=230,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=6, max_leaves=0, min_child_weight=4, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=1000, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor='auto', ...)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(random_state = 1, objective = \"binary:logistic\", eval_metric = \"logloss\", eta = 0.1, gamma = 2 , tree_method = \"gpu_hist\", \n",
    "                    max_bin = 230, max_depth = 6, min_child_weight = 4, subsample = .9, colsample_bytree = .8, learning_rate = .1,\n",
    "                    n_estimators = 1000)\n",
    "    \n",
    "xgb.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c0efd940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train log loss is: 0.3191114700789557\n",
      "The train precision is: 0.8093476144109055\n",
      "The validation log loss is: 0.3475345079939476\n",
      "The validation precision is: 0.7850367306183582\n",
      "The test log loss is: 0.35228207652931276\n",
      "The test precision is: 0.7791057367829022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 1, ..., 0, 0, 0]),\n",
       " array([[9.4799471e-01, 5.2005291e-02],\n",
       "        [4.5498025e-01, 5.4501975e-01],\n",
       "        [3.1273252e-01, 6.8726748e-01],\n",
       "        ...,\n",
       "        [7.8219104e-01, 2.1780893e-01],\n",
       "        [7.7900147e-01, 2.2099854e-01],\n",
       "        [9.9940223e-01, 5.9778703e-04]], dtype=float32),\n",
       " array([0, 0, 1, ..., 0, 0, 1]),\n",
       " array([[0.5817892 , 0.4182108 ],\n",
       "        [0.5515315 , 0.4484685 ],\n",
       "        [0.36105275, 0.63894725],\n",
       "        ...,\n",
       "        [0.9772966 , 0.02270339],\n",
       "        [0.7361076 , 0.26389238],\n",
       "        [0.44250673, 0.55749327]], dtype=float32),\n",
       " array([0, 1, 0, ..., 0, 1, 1]),\n",
       " array([[7.8975135e-01, 2.1024866e-01],\n",
       "        [4.2213517e-01, 5.7786483e-01],\n",
       "        [9.9991572e-01, 8.4295418e-05],\n",
       "        ...,\n",
       "        [6.6229057e-01, 3.3770946e-01],\n",
       "        [7.3259056e-02, 9.2674094e-01],\n",
       "        [3.4408629e-01, 6.5591371e-01]], dtype=float32))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    evaluate(xgb, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7238774d",
   "metadata": {},
   "source": [
    "## Output predicted probabilities for final model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1739085",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_probs_0 = [x[0] for x in preds_prob_train]\n",
    "test_probs_0 = [x[0] for x in preds_prob_test]\n",
    "\n",
    "pd.DataFrame(train_probs_0).to_csv('predictions_full_xgboost_train.csv', index = False)    \n",
    "pd.DataFrame(test_probs_0).to_csv('predictions_full_xgboost_test.csv', index = False)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db16fd45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

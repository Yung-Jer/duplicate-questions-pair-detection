{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from torchtext.legacy import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertModel\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "#from transformers import *\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wongy\\OneDrive\\Desktop\\duplicate-questions-pair-detection\n"
     ]
    }
   ],
   "source": [
    "abspath = os.path.abspath('')\n",
    "dname = os.path.dirname(abspath)\n",
    "os.chdir(dname)\n",
    "print(dname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_feather('data/processed/train_dataset.feather')\n",
    "test_df = pd.read_feather('data/processed/test_dataset.feather')\n",
    "val_df = pd.read_feather('data/processed/validation_dataset.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>q1_cleaned</th>\n",
       "      <th>q2_cleaned</th>\n",
       "      <th>q1_trimmed</th>\n",
       "      <th>q2_trimmed</th>\n",
       "      <th>q1_start</th>\n",
       "      <th>q2_start</th>\n",
       "      <th>length_diff</th>\n",
       "      <th>lc_substring</th>\n",
       "      <th>lc_subsequence</th>\n",
       "      <th>jaccard_dist</th>\n",
       "      <th>common_words</th>\n",
       "      <th>common_ratio</th>\n",
       "      <th>levenshtein</th>\n",
       "      <th>fuzz_qratio</th>\n",
       "      <th>fuzz_wratio</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400250</td>\n",
       "      <td>14340</td>\n",
       "      <td>533599</td>\n",
       "      <td>What movie website can I watch movies on witho...</td>\n",
       "      <td>what movie website can i watch movie on withou...</td>\n",
       "      <td>how can i watch movie online without a credit ...</td>\n",
       "      <td>what movie website can i watch movie on withou...</td>\n",
       "      <td>how can i watch movie online without a credit ...</td>\n",
       "      <td>what</td>\n",
       "      <td>how</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>44</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.057851</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67108</td>\n",
       "      <td>48332</td>\n",
       "      <td>116190</td>\n",
       "      <td>Is teleportation real?</td>\n",
       "      <td>is teleportation real</td>\n",
       "      <td>is teleportation possible</td>\n",
       "      <td>is teleportation real</td>\n",
       "      <td>is teleportation possible</td>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "      <td>-4</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>78</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>174821</td>\n",
       "      <td>269320</td>\n",
       "      <td>269321</td>\n",
       "      <td>What do foreigners think about China?</td>\n",
       "      <td>what do foreigner think about china</td>\n",
       "      <td>what do the most foreigner think about china</td>\n",
       "      <td>what do foreigner think about china</td>\n",
       "      <td>what do the most foreigner think about china</td>\n",
       "      <td>what</td>\n",
       "      <td>what</td>\n",
       "      <td>-9</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>6</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>0.886076</td>\n",
       "      <td>89</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>398717</td>\n",
       "      <td>531964</td>\n",
       "      <td>531965</td>\n",
       "      <td>Is Recep Tayyip Erdogan the greatest leader of...</td>\n",
       "      <td>is recep tayyip erdogan the greatest leader of...</td>\n",
       "      <td>why am i expected to do something in life</td>\n",
       "      <td>is recep tayyip erdogan the greatest leader of...</td>\n",
       "      <td>why am i expected to do something in life</td>\n",
       "      <td>is</td>\n",
       "      <td>why</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377358</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>187438</td>\n",
       "      <td>46329</td>\n",
       "      <td>42009</td>\n",
       "      <td>How do I improve my communication skills.?</td>\n",
       "      <td>how do i improve my communication skill</td>\n",
       "      <td>how can i improve my communication skill</td>\n",
       "      <td>how do i improve my communication skill</td>\n",
       "      <td>how can i improve my communication skill</td>\n",
       "      <td>how</td>\n",
       "      <td>how</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>37</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>6</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>0.936709</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index    qid1    qid2                                          question1  \\\n",
       "0  400250   14340  533599  What movie website can I watch movies on witho...   \n",
       "1   67108   48332  116190                             Is teleportation real?   \n",
       "2  174821  269320  269321              What do foreigners think about China?   \n",
       "3  398717  531964  531965  Is Recep Tayyip Erdogan the greatest leader of...   \n",
       "4  187438   46329   42009         How do I improve my communication skills.?   \n",
       "\n",
       "                                          q1_cleaned  \\\n",
       "0  what movie website can i watch movie on withou...   \n",
       "1                              is teleportation real   \n",
       "2                what do foreigner think about china   \n",
       "3  is recep tayyip erdogan the greatest leader of...   \n",
       "4            how do i improve my communication skill   \n",
       "\n",
       "                                          q2_cleaned  \\\n",
       "0  how can i watch movie online without a credit ...   \n",
       "1                          is teleportation possible   \n",
       "2       what do the most foreigner think about china   \n",
       "3          why am i expected to do something in life   \n",
       "4           how can i improve my communication skill   \n",
       "\n",
       "                                          q1_trimmed  \\\n",
       "0  what movie website can i watch movie on withou...   \n",
       "1                              is teleportation real   \n",
       "2                what do foreigner think about china   \n",
       "3  is recep tayyip erdogan the greatest leader of...   \n",
       "4            how do i improve my communication skill   \n",
       "\n",
       "                                          q2_trimmed q1_start q2_start  \\\n",
       "0  how can i watch movie online without a credit ...     what      how   \n",
       "1                          is teleportation possible       is       is   \n",
       "2       what do the most foreigner think about china     what     what   \n",
       "3          why am i expected to do something in life       is      why   \n",
       "4           how can i improve my communication skill      how      how   \n",
       "\n",
       "   length_diff  lc_substring  lc_subsequence  jaccard_dist  common_words  \\\n",
       "0           21            21              44      0.375000             7   \n",
       "1           -4            17              18      0.520000             2   \n",
       "2           -9            28              35      0.651163             6   \n",
       "3           24             2              20      0.000000             0   \n",
       "4            0            33              37      0.690476             6   \n",
       "\n",
       "   common_ratio  levenshtein  fuzz_qratio  fuzz_wratio  is_duplicate  \n",
       "0      0.057851     0.727273           73           81             1  \n",
       "1      0.043478     0.782609           78           82             0  \n",
       "2      0.075949     0.886076           89           95             1  \n",
       "3      0.000000     0.377358           38           38             0  \n",
       "4      0.075949     0.936709           94           94             1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def trim_sentence(sent):\n",
    "#     try:\n",
    "#         sent = sent.split()\n",
    "#         sent = sent[:128]\n",
    "#         return \" \".join(sent)\n",
    "#     except:\n",
    "#         return sent\n",
    "\n",
    "# train_df['q1_trimmed'] = train_df['q1_cleaned'].apply(lambda x: trim_sentence(x))\n",
    "# train_df['q2_trimmed'] = train_df['q2_cleaned'].apply(lambda x: trim_sentence(x))\n",
    "\n",
    "# val_df['q1_trimmed'] = val_df['q1_cleaned'].apply(lambda x: trim_sentence(x))\n",
    "# val_df['q2_trimmed'] = val_df['q2_cleaned'].apply(lambda x: trim_sentence(x))\n",
    "\n",
    "# test_df['q1_trimmed'] = test_df['q1_cleaned'].apply(lambda x: trim_sentence(x))\n",
    "# test_df['q2_trimmed'] = test_df['q2_cleaned'].apply(lambda x: trim_sentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def common_words(row):\n",
    "#     w1 = set(map(lambda word: word.lower().strip(), row['q1_cleaned'].split(\" \")))\n",
    "#     w2 = set(map(lambda word: word.lower().strip(), row['q2_cleaned'].split(\" \")))    \n",
    "#     return len(w1 & w2)\n",
    "    \n",
    "# df['jaccard_dist'] = nltk.jaccard_distance(set(df['q1_cleaned']), set(df['q2_cleaned']))\n",
    "# df['common_words'] = df.apply(common_words, axis=1)\n",
    "# df['common_ratio'] = df.apply(lambda row: row['common_words'] / (len(row['q1_cleaned']) + len(row['q2_cleaned'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masking the tokens to feed into BERT\n",
    "def sent1_token_type(sentence):\n",
    "    try:\n",
    "        return [0]* len(sentence)\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "#Get list of 1s\n",
    "def sent2_token_type(sentence):\n",
    "    try:\n",
    "        return [1]* len(sentence)\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "#combine from lists\n",
    "def combine_seq(seq):\n",
    "    return \" \".join(seq)\n",
    "\n",
    "#combines from lists of int\n",
    "def combine_mask(mask):\n",
    "    mask = list(map(str, mask))\n",
    "    return \" \".join(mask)\n",
    "\n",
    "#convert attention mask back to list of int\n",
    "def convert_mask(tok_ids):\n",
    "    tok_ids = [int(x) for x in tok_ids]\n",
    "    return tok_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "cls_token = tokenizer.cls_token\n",
    "sep_token = tokenizer.sep_token\n",
    "pad_token = tokenizer.pad_token\n",
    "unk_token = tokenizer.unk_token\n",
    "cls_token_idx = tokenizer.cls_token_id\n",
    "sep_token_idx = tokenizer.sep_token_id\n",
    "pad_token_idx = tokenizer.pad_token_id\n",
    "unk_token_idx = tokenizer.unk_token_id\n",
    "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
    "\n",
    "def tokenize_bert(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence) \n",
    "    return tokens\n",
    "\n",
    "\n",
    "def split_and_cut(sentence):\n",
    "    tokens = sentence.strip().split(\" \")\n",
    "    tokens = tokens[:max_input_length] # make sure that it does not overflow\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['q1_padded'] = '[CLS] ' + train_df['q1_trimmed'] + ' [SEP] '\n",
    "train_df['q2_padded'] = train_df['q2_trimmed'] + ' [SEP]'\n",
    "\n",
    "train_df['q1_bert_tokens'] = train_df['q1_padded'].apply(lambda x: tokenize_bert(x))\n",
    "train_df['q2_bert_tokens'] = train_df['q2_padded'].apply(lambda x: tokenize_bert(x))\n",
    "\n",
    "val_df['q1_padded'] = '[CLS] ' + val_df['q1_trimmed'] + ' [SEP] '\n",
    "val_df['q2_padded'] = val_df['q2_trimmed'] + ' [SEP]'\n",
    "\n",
    "val_df['q1_bert_tokens'] = val_df['q1_padded'].apply(lambda x: tokenize_bert(x))\n",
    "val_df['q2_bert_tokens'] = val_df['q2_padded'].apply(lambda x: tokenize_bert(x))\n",
    "\n",
    "test_df['q1_padded'] = '[CLS] ' + test_df['q1_trimmed'] + ' [SEP] '\n",
    "test_df['q2_padded'] = test_df['q2_trimmed'] + ' [SEP]'\n",
    "\n",
    "test_df['q1_bert_tokens'] = test_df['q1_padded'].apply(lambda x: tokenize_bert(x))\n",
    "test_df['q2_bert_tokens'] = test_df['q2_padded'].apply(lambda x: tokenize_bert(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['q1_token_type'] = train_df['q1_bert_tokens'].apply(lambda x: sent1_token_type(x))\n",
    "train_df['q2_token_type'] = train_df['q2_bert_tokens'].apply(lambda x: sent2_token_type(x))\n",
    "\n",
    "val_df['q1_token_type'] = val_df['q1_bert_tokens'].apply(lambda x: sent1_token_type(x))\n",
    "val_df['q2_token_type'] = val_df['q2_bert_tokens'].apply(lambda x: sent2_token_type(x))\n",
    "\n",
    "test_df['q1_token_type'] = test_df['q1_bert_tokens'].apply(lambda x: sent1_token_type(x))\n",
    "test_df['q2_token_type'] = test_df['q2_bert_tokens'].apply(lambda x: sent2_token_type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['sequence'] = train_df['q1_bert_tokens'] + train_df['q2_bert_tokens']\n",
    "train_df['attn_mask'] = train_df['sequence'].apply(lambda x: sent2_token_type(x)) # every word needs attention\n",
    "train_df['token_type'] = train_df['q1_token_type'] + train_df['q2_token_type']\n",
    "\n",
    "val_df['sequence'] = val_df['q1_bert_tokens'] + val_df['q2_bert_tokens']\n",
    "val_df['attn_mask'] = val_df['sequence'].apply(lambda x: sent2_token_type(x)) # every word needs attention\n",
    "val_df['token_type'] = val_df['q1_token_type'] + val_df['q2_token_type']\n",
    "\n",
    "test_df['sequence'] = test_df['q1_bert_tokens'] + test_df['q2_bert_tokens']\n",
    "test_df['attn_mask'] = test_df['sequence'].apply(lambda x: sent2_token_type(x)) # every word needs attention\n",
    "test_df['token_type'] = test_df['q1_token_type'] + test_df['q2_token_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all the inputs to be sequential in string instead of list\n",
    "train_df['sequence'] = train_df['sequence'].apply(lambda x: combine_seq(x))\n",
    "train_df['attn_mask'] = train_df['attn_mask'].apply(lambda x: combine_mask(x))\n",
    "train_df['token_type'] = train_df['token_type'].apply(lambda x: combine_mask(x))\n",
    "\n",
    "val_df['sequence'] = val_df['sequence'].apply(lambda x: combine_seq(x))\n",
    "val_df['attn_mask'] = val_df['attn_mask'].apply(lambda x: combine_mask(x))\n",
    "val_df['token_type'] = val_df['token_type'].apply(lambda x: combine_mask(x))\n",
    "\n",
    "test_df['sequence'] = test_df['sequence'].apply(lambda x: combine_seq(x))\n",
    "test_df['attn_mask'] = test_df['attn_mask'].apply(lambda x: combine_mask(x))\n",
    "test_df['token_type'] = test_df['token_type'].apply(lambda x: combine_mask(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For sequence\n",
    "TEXT = data.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = split_and_cut,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  pad_token = pad_token_idx,\n",
    "                  unk_token = unk_token_idx)\n",
    "#For label\n",
    "LABEL = data.LabelField()\n",
    "\n",
    "#For Attention mask\n",
    "ATTENTION = data.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = split_and_cut,\n",
    "                  preprocessing = convert_mask,\n",
    "                  pad_token = pad_token_idx)\n",
    "#For token type ids\n",
    "TTYPE = data.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = split_and_cut,\n",
    "                  preprocessing = convert_mask,\n",
    "                  pad_token = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[['sequence', 'attn_mask', 'token_type', 'is_duplicate']]\n",
    "val_df = val_df[['sequence', 'attn_mask', 'token_type', 'is_duplicate']]\n",
    "test_df = test_df[['sequence', 'attn_mask', 'token_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('data/processed/bert_train.csv', index = False)\n",
    "val_df.to_csv('data/processed/bert_val.csv', index = False)\n",
    "test_df.to_csv('data/processed/bert_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "fields = [('sequence', TEXT), ('attn_mask', ATTENTION), ('token_type', TTYPE), ('is_duplicate', LABEL)]\n",
    "\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(path = 'data/processed/',\n",
    "                                                    train = 'bert_train.csv',\n",
    "                                                    validation = 'bert_val.csv',\n",
    "                                                    test = 'bert_test.csv',\n",
    "                                                    format = 'csv',\n",
    "                                                    fields = fields,\n",
    "                                                    skip_header = True)\n",
    "#Create iterator\n",
    "BATCH_SIZE = 16\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator, test_iterator= data.BucketIterator.splits((train_data, valid_data, test_data), \n",
    "                                                            batch_size = BATCH_SIZE,\n",
    "                                                            sort_key = lambda x: len(x.sequence),\n",
    "                                                            sort_within_batch = False, \n",
    "                                                            device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "LABEL.build_vocab(train_data)\n",
    "print(len(LABEL.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTNLIModel(nn.Module):\n",
    "    def __init__(self, bert_model, output_dim):\n",
    "        super().__init__()\n",
    "        self.bert = bert_model\n",
    "        embedding_dim = bert_model.config.to_dict()['hidden_size']\n",
    "        self.out = nn.Linear(embedding_dim, output_dim)\n",
    "        \n",
    "    def forward(self, sequence, attn_mask, token_type):\n",
    "        embedded = self.bert(input_ids=sequence, attention_mask=attn_mask, token_type_ids=token_type)[1]\n",
    "        output = self.out(embedded)\n",
    "        return output\n",
    "\n",
    "OUTPUT_DIM = len(LABEL.vocab)\n",
    "model = BERTNLIModel(bert_model, OUTPUT_DIM).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wongy\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = transformers.AdamW(model.parameters(),lr=2e-5,eps=1e-6,correct_bias=False)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "def get_scheduler(optimizer, warmup_steps):\n",
    "    scheduler = transformers.get_constant_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps)\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y):\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True)\n",
    "\n",
    "    correct = (max_preds.squeeze(1)==y).float()\n",
    "\n",
    "    return correct.sum() / len(y)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, scheduler):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad() # clear gradients first\n",
    "        torch.cuda.empty_cache() # releases all unoccupied cached memory\n",
    "        \n",
    "        sequence = batch.sequence\n",
    "        attn_mask = batch.attn_mask\n",
    "        token_type = batch.token_type\n",
    "        label = batch.is_duplicate\n",
    "        \n",
    "        predictions = model(sequence, attn_mask, token_type)\n",
    "        loss = criterion(predictions, label)\n",
    "        acc = categorical_accuracy(predictions, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            sequence = batch.sequence\n",
    "\n",
    "            attn_mask = batch.attn_mask\n",
    "            token_type = batch.token_type\n",
    "            labels = batch.is_duplicate\n",
    "\n",
    "            predictions = model(sequence, attn_mask, token_type)\n",
    "            loss = criterion(predictions, labels)\n",
    "            acc = categorical_accuracy(predictions, labels)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [24], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N_EPOCHS):\n\u001b[0;32m      9\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> 10\u001b[0m     train_loss, train_acc \u001b[39m=\u001b[39m train(model, train_iterator, optimizer, criterion, scheduler)\n\u001b[0;32m     11\u001b[0m     valid_loss, valid_acc \u001b[39m=\u001b[39m evaluate(model, valid_iterator, criterion)\n\u001b[0;32m     12\u001b[0m     end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "Cell \u001b[1;32mIn [23], line 32\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, iterator, optimizer, criterion, scheduler)\u001b[0m\n\u001b[0;32m     29\u001b[0m acc \u001b[39m=\u001b[39m categorical_accuracy(predictions, label)\n\u001b[0;32m     31\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m---> 32\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m     33\u001b[0m scheduler\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     35\u001b[0m epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\wongy\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:65\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     64\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\wongy\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\optim\\optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m     87\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\wongy\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\optimization.py:360\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    356\u001b[0m state[\u001b[39m\"\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    358\u001b[0m \u001b[39m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[39m# In-place operations to update the averages at the same time\u001b[39;00m\n\u001b[1;32m--> 360\u001b[0m exp_avg\u001b[39m.\u001b[39;49mmul_(beta1)\u001b[39m.\u001b[39madd_(grad, alpha\u001b[39m=\u001b[39m(\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m beta1))\n\u001b[0;32m    361\u001b[0m exp_avg_sq\u001b[39m.\u001b[39mmul_(beta2)\u001b[39m.\u001b[39maddcmul_(grad, grad, value\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m beta2)\n\u001b[0;32m    362\u001b[0m denom \u001b[39m=\u001b[39m exp_avg_sq\u001b[39m.\u001b[39msqrt()\u001b[39m.\u001b[39madd_(group[\u001b[39m\"\u001b[39m\u001b[39meps\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "warmup_percent = 0.2\n",
    "total_steps = math.ceil(N_EPOCHS*len(train_data)*1./BATCH_SIZE)\n",
    "warmup_steps = int(total_steps*warmup_percent)\n",
    "scheduler = get_scheduler(optimizer, warmup_steps)\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, scheduler)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'bert_based_quora_model.pt')\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('src/bert_based_quora_model.pt'))\n",
    "val_loss, val_acc = evaluate(model, valid_iterator, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'bert_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_inference(q1, q2, model, device):\n",
    "    model.eval()\n",
    "    \n",
    "    q1 = '[CLS] ' + str(q1) + ' [SEP]'\n",
    "    q2 = str(q2) + ' [SEP]'\n",
    "    \n",
    "    q1_t = tokenize_bert(q1)\n",
    "    q2_t = tokenize_bert(q2)\n",
    "    \n",
    "    q1_type = sent1_token_type(q1_t)\n",
    "    q2_type = sent2_token_type(q2_t)\n",
    "    \n",
    "    indexes = q1_t + q2_t\n",
    "    indexes = tokenizer.convert_tokens_to_ids(indexes)\n",
    "    \n",
    "    indexes_type = q1_type + q2_type\n",
    "    \n",
    "    attn_mask = sent2_token_type(indexes)\n",
    "    \n",
    "    indexes = torch.LongTensor(indexes).unsqueeze(0).to(device)\n",
    "    indexes_type = torch.LongTensor(indexes_type).unsqueeze(0).to(device)\n",
    "    attn_mask = torch.LongTensor(attn_mask).unsqueeze(0).to(device)\n",
    "    \n",
    "    prediction = model(indexes, attn_mask, indexes_type)\n",
    "    # prediction = prediction.argmax(dim=-1).item()\n",
    "    return prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "4773a713a8d9157baa5060563bb30fcc500d9ac4a3c23c64afa2c361e1e3f31c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
